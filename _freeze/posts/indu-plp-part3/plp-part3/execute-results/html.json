{
  "hash": "0c32f2759da46352a00eee8fd8221f36",
  "result": {
    "engine": "julia",
    "markdown": "---\ntitle: \"PLP-Pipeline Series Part 3: Lessons Learned, Key Challenges, and What Comes Next\"\ndescription: \"Reflections on building an end-to-end PLP pipeline in Julia tools - lessons learned, current challenges, and future directions.\"  \nauthor: \"Kosuri Lakshmi Indu\"\ndate: \"4/21/2025\"\nbibliography: ./references.bib\ncsl: ./../../ieee-with-url.csl\ntoc: true\nengine: julia\nimage: false\ncategories:\n  - patient-level prediction\n  - omop cdm\n  - observational health\n---\n\n\n\n# Introduction üëã\n\nWelcome back to the final part of the blog series on building a Patient-Level Prediction (PLP) Pipeline in Julia using the OMOP Common Data Model (CDM).\n\nIn this concluding post, we'll reflect on the full journey - from cohort definition and feature extraction to preprocessing, modeling, and evaluation. We'll dig into what worked well, what challenges emerged, and what lessons were learned while building this pipeline from scratch using Julia. This post aims to bring the series full circle, offering insights into the practical realities of working with real-world health data and setting the stage for future work and improvements.\n\n## Recap of Previous Parts\n\nIn [**Part 1**](../indu-plp-part1/plp-part1.qmd), we introduced the motivation and core question driving the pipeline:\n\n> Among patients diagnosed with hypertension, who will go on to develop diabetes?\n\nWe chose this prediction problem because of its clinical relevance and because hypertension and diabetes are both common chronic conditions with strong associations in literature.\n\nTo extract patient cohorts, we used [`OHDSICohortExpressions.jl`](https://github.com/MechanicalRabbit/OHDSICohortExpressions.jl), which allowed us to define concept sets and logic for cohort inclusion and exclusion. For example, the hypertension target cohort included patients with a confirmed hypertension diagnosis, and the outcome cohort included those later diagnosed with diabetes.\n\n\nIn [**Part 2**](../indu-plp-part2/plp-part2.qmd), we built a modular pipeline using the Julia ecosystem:\n\n- **Feature extraction** involved pulling demographic, condition, drug, and visit data, encoding it as binary presence indicators.\n- **Preprocessing** included handling missing values, one-hot encoding, normalization, and creating train-test splits.\n- **Model training** used the `MLJ.jl` framework to train logistic regression, random forest, and XGBoost models.\n- **Evaluation** involved computing AUC and accuracy for binary classification.\n\n## Reflections on the OHDSI Framework vs Julia Approach\n\nThe OHDSI ecosystem, particularly its [`PatientLevelPrediction`](https://github.com/OHDSI/PatientLevelPrediction) package in R, offers an end-to-end solution that integrates tightly with ATLAS and standardized vocabularies. It handles cohort creation, covariate extraction, modeling, and visualization all in one environment.\n\nIn contrast, building this pipeline in Julia offered greater flexibility by composing modular packages for each step from cohort extraction and feature engineering to model training and evaluation‚Äîrather than relying on a single integrated tool like OHDSI‚Äôs `PatientLevelPrediction` package in R. While this required more manual implementation, it gave me deeper insight into how design decisions impacted performance and reproducibility. Using Julia‚Äôs ecosystem (e.g., `DataFrames.jl`, `MLJ.jl`), I could customize the workflow and experiment with different modeling strategies. To give a complete picture of the pipeline‚Äôs outcome, I‚Äôve included relevant performance statistics and visualizations, even where the results were suboptimal.\n\n## Model performance\n\nAfter preprocessing the features and labels, model performance was not as strong as expected. The AUC values for the classifiers were relatively low for the models:\n\n- Logistic Regression (L1-regularized)\n- Random Forest: AUC \n- XGBoost: AUC\n\nThese unexpectedly low model performances prompted a deeper investigation into the root causes. The primary issue was that the **data available in the CDM was not well-suited** to answer the research question: ‚ÄúFrom those diagnosed with hypertension, who goes on to develop diabetes?‚Äù \n\nTemporal context was also missing, as the features extracted were basic binary indicators that did not reflect the timing or frequency of clinical events. The one-year prediction window might have been too narrow for diabetes to develop meaningfully after a hypertension diagnosis. \n\nAdditionally, many patients had very limited observational data before the index date, reducing the reliability of the features. Altogether, the problem lay not with the modeling itself but with the mismatch between the available data and the clinical nuances of the question being asked.\n\n## Lessons Learned\n\nThis project highlighted that Julia is well-suited for observational health research workflows. Its strong data ecosystem (`DataFrames.jl`, `DuckDB.jl`, `CSV.jl`), rich machine learning interfaces (`MLJ.jl`), and increasing support from domain-specific packages like `OHDSICohortExpressions.jl` make it a compelling environment for building transparent, customizable pipelines. Unlike black-box tools, Julia allows full control over every stage-from data access to model tuning-encouraging deeper understanding and reproducibility.\n\nFrom this experience, several lessons became evident:\n\n- Even with a standardized data model like OMOP CDM, **cohort construction requires clinical reasoning and thorough validation**. Poorly defined cohorts can introduce significant noise and reduce the quality of the learning task.\n- **Simple features such as binary flags often fail** to capture the complex temporal and contextual dynamics in longitudinal health data.\n- **Model performance depends on the entire pipeline**, not just the algorithm. Label noise, data completeness, and preprocessing choices all significantly impact the results.\n- **Reproducibility is essential**-having modular code and clearly defined steps ensures that results can be validated, shared, and extended by others in the community.\n\n\n## Key Challenges Faced\n\nThroughout the process, we encountered several technical and conceptual challenges:\n\nThe most critical issue lay in the **quality and structure of the data itself**. Many patients had sparse or short observation periods, which meant that only limited clinical history was available before the cohort entry date. \n\nThis directly affected the utility of the extracted features. On the modeling side, integrating with `MLJ.jl` required careful setup, especially when handling missing values, categorical encodings, and class imbalance.\n\n<br>\n<center>\n  ![](./mlj.png)\n\n  MLJ.jl\n</center>\n<br>\n\nFeature engineering was another bottleneck, since most features were binary flags or simple counts that did not capture clinical nuance or temporal dynamics. Preprocessing steps like normalization and imputation also needed fine-tuning and often had to be manually adjusted per model. \n\n## Next Steps for the Pipeline\n\nTo address the above challenges and build on the current foundation, the next steps could include:\n\n- **Refining cohort definitions**:\n  - Ensure outcome definitions require multiple confirmations or additional evidence (e.g., lab tests or prescriptions).\n  - Consider longer lookahead and lookback windows for a richer temporal view of patient history.\n- **Improving feature extraction**:\n  - Add time-to-event features, visit counts, or recency indicators.\n  - Explore embedding-based representations of condition or drug sequences.\n- **Extending evaluation**:\n  - Use calibration plots, ROC/PR curves, and stratified performance metrics.\n  - Evaluate model fairness across subgroups (age, sex, race if available).\n- **Visualization and reporting**:\n  - Add support for plotting cohort sizes, timelines, and model performance.\n  - Use libraries like `Makie.jl` or `VegaLite.jl` to generate interactive plots.\n- **Code modularization**:\n  - Refactor the current pipeline into reusable, well-documented modules.\n  - Provide clear examples, unit tests, and reproducible workflows.\n\n## Looking Ahead\n\nThis project was both a technical and conceptual deep dive into building patient-level prediction tools from scratch in Julia. Although the first iteration of the models underperformed, the experience revealed what is required to do such predictive modeling properly: validated cohorts, thoughtful feature engineering, strong modeling baselines, and interpretable results.\n\nThe long-term goal is to turn this exploratory code into a robust, Julia-native package for PLP tasks - one that integrates with existing JuliaHealth tools, supports OMOP CDM datasets, and provides flexibility for building custom pipelines. By aligning more closely with OHDSI definitions and adding diagnostics, this could serve as both a research tool and an educational resource.\n\nTo improve interpretability, we could also incorporate visualization into the pipeline using tools like `Makie.jl` or `VegaLite.jl`. Some of the visualizations that can enhance understanding include:\n\n- Timeline plots showing cohort entry and outcome windows\n- Feature density plots to understand sparsity\n- ROC and PR curves to assess model quality\n- Feature importance summaries from tree-based models\n\nThese will not only support model tuning but also help communicate findings to clinicians and researchers.\n\nEventually, this project could serve as a foundation for a Julia-native PLP toolkit, or at least a template for others interested in working with observational health data in Julia.\n\n# Thank You\n\nIf you‚Äôve followed the blog series till now - thank you. Your time and interest in this work mean a lot. I hope this series helped you understand what it takes to build predictive models using real-world health data, and how Julia can support that process in a flexible and open way.\n\nFeel free to connect  connect with me on [**LinkedIn**](https://www.linkedin.com/in/kosuri-indu/) and follow me on [**GitHub**](https://github.com/kosuri-indu)\n\n## Acknowledgements\n\nThanks to Jacob Zelko for his mentorship, clarity, and constant feedback throughout the project. I also thank the JuliaHealth community for building an ecosystem where composable science can thrive.\n\n[Jacob S. Zelko](https://jacobzelko.com): aka, [TheCedarPrince](https://github.com/TheCedarPrince)\n\n_Note: This blog post was drafted with the assistance of LLM technologies to support grammar, clarity and structure._\n\n",
    "supporting": [
      "plp-part3_files"
    ],
    "filters": [],
    "includes": {}
  }
}